{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('TSLA_stock_data_2023.csv')\n",
    "# data_day = pd.read.csv('TSLA_stock_data_day_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32448/2680987495.py:2: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  data['Datetime'] = pd.to_datetime(data['Datetime'])\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'Datetime' is a datetime object\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# Initialize empty lists for states and predict_price\n",
    "states = []\n",
    "predict_prices = []\n",
    "\n",
    "# Set your rolling window size (3 days)\n",
    "rolling_window_size = 3\n",
    "\n",
    "# Start your window from the beginning of the data\n",
    "current_start_index = 0\n",
    "\n",
    "# Calculate the end index for the first window\n",
    "current_end_index = rolling_window_size * 24  # assuming hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1051e+02, 1.1133e+02, 1.0744e+02, 1.0842e+02, 4.9873e+07, 1.0841e+02,\n",
      "        1.0896e+02, 1.0716e+02, 1.0860e+02, 2.2871e+07, 1.0859e+02, 1.1052e+02,\n",
      "        1.0836e+02, 1.0999e+02, 2.0578e+07, 1.0998e+02, 1.1175e+02, 1.0921e+02,\n",
      "        1.1108e+02, 1.8166e+07, 1.1109e+02, 1.1145e+02, 1.1010e+02, 1.1012e+02,\n",
      "        1.6738e+07, 1.1011e+02, 1.1133e+02, 1.0997e+02, 1.1059e+02, 1.7126e+07,\n",
      "        1.1060e+02, 1.1086e+02, 1.1006e+02, 1.1037e+02, 8.7495e+06, 1.0300e+02,\n",
      "        1.0755e+02, 1.0181e+02, 1.0580e+02, 7.4858e+07, 1.0579e+02, 1.0980e+02,\n",
      "        1.0560e+02, 1.0970e+02, 3.0898e+07, 1.0971e+02, 1.1292e+02, 1.0920e+02,\n",
      "        1.1181e+02, 3.0720e+07, 1.1181e+02, 1.1226e+02, 1.1023e+02, 1.1114e+02,\n",
      "        2.3984e+07, 1.1113e+02, 1.1313e+02, 1.1107e+02, 1.1281e+02, 1.8755e+07,\n",
      "        1.1280e+02, 1.1439e+02, 1.1273e+02, 1.1312e+02, 2.3543e+07, 1.1312e+02,\n",
      "        1.1360e+02, 1.1245e+02, 1.1303e+02, 1.3833e+07, 1.1896e+02, 1.2305e+02,\n",
      "        1.1711e+02, 1.2162e+02, 6.7552e+07, 1.2161e+02, 1.2333e+02, 1.2142e+02,\n",
      "        1.2211e+02, 2.8621e+07, 1.2213e+02, 1.2260e+02, 1.2088e+02, 1.2203e+02,\n",
      "        1.7547e+07, 1.2204e+02, 1.2352e+02, 1.2101e+02, 1.2321e+02, 1.7986e+07,\n",
      "        1.2321e+02, 1.2324e+02, 1.2072e+02, 1.2177e+02, 2.1303e+07, 1.2178e+02,\n",
      "        1.2201e+02, 1.1978e+02, 1.2058e+02, 1.9848e+07, 1.2059e+02, 1.2076e+02,\n",
      "        1.1926e+02, 1.1979e+02, 1.1509e+07, 1.2113e+02, 1.2276e+02, 1.1736e+02,\n",
      "        1.1786e+02, 5.4363e+07, 1.1785e+02, 1.1787e+02, 1.1492e+02, 1.1658e+02,\n",
      "        3.1595e+07, 1.1657e+02, 1.1704e+02, 1.1571e+02, 1.1612e+02, 1.6565e+07,\n",
      "        1.1611e+02, 1.1805e+02, 1.1604e+02, 1.1752e+02, 1.7280e+07, 1.1752e+02,\n",
      "        1.1825e+02, 1.1701e+02, 1.1770e+02, 1.6028e+07, 1.1771e+02, 1.1793e+02,\n",
      "        1.1665e+02, 1.1758e+02, 1.5313e+07, 1.1758e+02, 1.1888e+02, 1.1758e+02,\n",
      "        1.1885e+02, 1.2819e+07, 1.2209e+02, 1.2595e+02, 1.2051e+02, 1.2506e+02,\n",
      "        6.1053e+07, 1.2504e+02, 1.2506e+02, 1.2205e+02, 1.2264e+02, 3.4945e+07,\n",
      "        1.2262e+02, 1.2339e+02, 1.2220e+02, 1.2252e+02, 1.7872e+07, 1.2254e+02,\n",
      "        1.2278e+02, 1.2150e+02, 1.2205e+02, 1.8844e+07, 1.2204e+02, 1.2258e+02,\n",
      "        1.2164e+02, 1.2208e+02, 1.4025e+07, 1.2207e+02, 1.2290e+02, 1.2128e+02,\n",
      "        1.2287e+02, 1.8951e+07, 1.2288e+02, 1.2327e+02, 1.2214e+02, 1.2321e+02,\n",
      "        1.3549e+07, 1.2256e+02, 1.2292e+02, 1.1700e+02, 1.1959e+02, 5.7946e+07,\n",
      "        1.1960e+02, 1.2037e+02, 1.1861e+02, 1.1958e+02, 2.1781e+07, 1.1959e+02,\n",
      "        1.2148e+02, 1.1906e+02, 1.2116e+02, 1.7734e+07, 1.2115e+02, 1.2148e+02,\n",
      "        1.2000e+02, 1.2039e+02, 1.5020e+07, 1.2038e+02, 1.2314e+02, 1.1984e+02,\n",
      "        1.2286e+02, 2.0809e+07, 1.2286e+02, 1.2413e+02, 1.2233e+02, 1.2294e+02,\n",
      "        2.0541e+07, 1.2295e+02, 1.2381e+02, 1.2271e+02, 1.2352e+02, 1.1546e+07,\n",
      "        1.1655e+02, 1.1992e+02, 1.1560e+02, 1.1990e+02, 6.5217e+07, 1.1989e+02,\n",
      "        1.2166e+02, 1.1859e+02, 1.1915e+02, 3.1198e+07, 1.1913e+02, 1.2115e+02,\n",
      "        1.1837e+02, 1.2063e+02, 1.8890e+07, 1.2061e+02, 1.2141e+02, 1.1995e+02,\n",
      "        1.2043e+02, 1.6980e+07, 1.2044e+02, 1.2133e+02, 1.2022e+02, 1.2082e+02,\n",
      "        1.5084e+07, 1.2081e+02, 1.2228e+02, 1.2051e+02, 1.2220e+02, 1.6476e+07,\n",
      "        1.2220e+02, 1.2263e+02, 1.2168e+02, 1.2237e+02, 1.3393e+07, 1.2569e+02,\n",
      "        1.3058e+02, 1.2502e+02, 1.2954e+02, 6.1834e+07, 1.2954e+02, 1.2989e+02,\n",
      "        1.2743e+02, 1.2852e+02, 2.7007e+07, 1.2852e+02, 1.2968e+02, 1.2848e+02,\n",
      "        1.2943e+02, 1.8603e+07, 1.2943e+02, 1.3137e+02, 1.2928e+02, 1.3045e+02,\n",
      "        2.0965e+07, 1.3046e+02, 1.3139e+02, 1.3010e+02, 1.3045e+02, 1.9079e+07,\n",
      "        1.3045e+02, 1.3129e+02, 1.3039e+02, 1.3105e+02, 1.8520e+07, 1.3104e+02,\n",
      "        1.3170e+02, 1.3093e+02, 1.3147e+02, 1.4017e+07, 1.3655e+02, 1.3668e+02,\n",
      "        1.3211e+02, 1.3243e+02, 6.2743e+07, 1.3245e+02, 1.3319e+02, 1.2865e+02,\n",
      "        1.2924e+02, 3.8308e+07, 1.2928e+02, 1.3047e+02, 1.2831e+02, 1.2935e+02,\n",
      "        2.4329e+07, 1.2934e+02, 1.2935e+02, 1.2701e+02, 1.2781e+02, 2.1715e+07,\n",
      "        1.2780e+02, 1.2845e+02, 1.2726e+02, 1.2817e+02, 1.7260e+07, 1.2817e+02,\n",
      "        1.2913e+02, 1.2800e+02, 1.2866e+02, 1.6894e+07, 1.2865e+02, 1.2893e+02,\n",
      "        1.2797e+02, 1.2875e+02, 1.0807e+07, 1.2790e+02, 1.2999e+02, 1.2682e+02,\n",
      "        1.2768e+02, 4.9078e+07, 1.2769e+02, 1.2803e+02, 1.2505e+02, 1.2524e+02,\n",
      "        3.0814e+07, 1.2522e+02, 1.2638e+02, 1.2431e+02, 1.2575e+02, 2.4814e+07,\n",
      "        1.2574e+02, 1.2754e+02, 1.2557e+02, 1.2679e+02, 1.8056e+07, 1.2678e+02,\n",
      "        1.2854e+02, 1.2677e+02, 1.2828e+02, 1.8658e+07, 1.2830e+02, 1.2872e+02,\n",
      "        1.2718e+02, 1.2774e+02, 1.6105e+07, 1.2774e+02, 1.2780e+02, 1.2696e+02,\n",
      "        1.2716e+02, 9.0869e+06, 1.2868e+02, 1.3169e+02, 1.2735e+02, 1.3100e+02,\n",
      "        4.3905e+07, 1.3098e+02, 1.3144e+02, 1.2962e+02, 1.3131e+02, 2.2856e+07])\n",
      "tensor([131.3100])\n"
     ]
    }
   ],
   "source": [
    "while current_end_index < len(data):\n",
    "    # Get the current window of data\n",
    "    current_window = data.iloc[current_start_index:current_end_index]\n",
    "    \n",
    "    # Flatten the data from the current window and append it to states\n",
    "    window_features = current_window[['Open', 'High', 'Low', 'Close', 'Volume']].values.flatten()\n",
    "    states.append(window_features)\n",
    "    \n",
    "    # We assume 'Close' price is what we want to predict and use the last 'Close' price of the current window\n",
    "    predict_prices.append(current_window.iloc[-1]['Close'])\n",
    "    \n",
    "    # Move the window one day forward\n",
    "    current_start_index += 7  # assuming hourly data\n",
    "    current_end_index += 7\n",
    "# Convert the lists to NumPy arrays\n",
    "states = np.array(states)\n",
    "predict_prices = np.array(predict_prices)\n",
    "\n",
    "# Convert arrays to tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "predict_prices_tensor = torch.tensor(predict_prices, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Now you can check the first state and price\n",
    "print(states_tensor[2])  # First state\n",
    "print(predict_prices_tensor[2])  # First price to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.54490005e+02, 2.56980011e+02, 2.52910004e+02, 2.56170013e+02,\n",
       "        2.35974050e+07, 2.56160004e+02, 2.57479004e+02, 2.55389999e+02,\n",
       "        2.56394989e+02, 1.63013580e+07, 2.56409698e+02, 2.57519012e+02,\n",
       "        2.56100006e+02, 2.57445007e+02, 1.09132680e+07, 2.57440186e+02,\n",
       "        2.57820007e+02, 2.56589996e+02, 2.57720001e+02, 1.00004970e+07,\n",
       "        2.57730011e+02, 2.57970001e+02, 2.57210205e+02, 2.57502991e+02,\n",
       "        7.48659400e+06, 2.57510010e+02, 2.57630005e+02, 2.56179993e+02,\n",
       "        2.56855011e+02, 9.02844900e+06, 2.56869995e+02, 2.57459991e+02,\n",
       "        2.56339996e+02, 2.56709991e+02, 6.31647400e+06, 2.58350006e+02,\n",
       "        2.63339996e+02, 2.57519989e+02, 2.62839996e+02, 3.54315110e+07,\n",
       "        2.62829987e+02, 2.62950012e+02, 2.60690002e+02, 2.62250000e+02,\n",
       "        1.76088960e+07, 2.62244995e+02, 2.62959991e+02, 2.61920013e+02,\n",
       "        2.62464996e+02, 1.03576300e+07, 2.62480011e+02, 2.62920013e+02,\n",
       "        2.61829987e+02, 2.62842896e+02, 9.86631300e+06, 2.62850006e+02,\n",
       "        2.63249908e+02, 2.61609985e+02, 2.62239899e+02, 1.04377090e+07,\n",
       "        2.62239990e+02, 2.62440002e+02, 2.60142487e+02, 2.60589996e+02,\n",
       "        9.09913300e+06, 2.60579987e+02, 2.61549988e+02, 2.60450012e+02,\n",
       "        2.61549988e+02, 1.00756260e+07, 2.63660004e+02, 2.65130005e+02,\n",
       "        2.59820007e+02, 2.60876801e+02, 3.24311360e+07, 2.60870087e+02,\n",
       "        2.61760010e+02, 2.58600006e+02, 2.59000000e+02, 1.78276340e+07,\n",
       "        2.59000000e+02, 2.59420013e+02, 2.58299988e+02, 2.58980011e+02,\n",
       "        1.15633090e+07, 2.58980011e+02, 2.59869995e+02, 2.56480011e+02,\n",
       "        2.56692993e+02, 1.30463230e+07, 2.56705292e+02, 2.57179901e+02,\n",
       "        2.55440002e+02, 2.56010010e+02, 1.08631660e+07, 2.56019989e+02,\n",
       "        2.56070007e+02, 2.52710007e+02, 2.53965500e+02, 1.53134970e+07,\n",
       "        2.53960007e+02, 2.54479996e+02, 2.52800003e+02, 2.53190002e+02,\n",
       "        9.11528200e+06]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert state.shape[0] == predict_price.shape[0], \"The number of samples should be the same.\"\n",
    "# Now, use train_test_split\n",
    "state_train, state_test, predict_price_train, predict_price_test = train_test_split(\n",
    "    state, predict_price, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# # divide the data into training part and test part\n",
    "# state_train, state_test, predict_price_train,predict_price_test= train_test_split(state, predict_price,test_size=0.2, random_state=42)\n",
    "# train_loader = DataLoader(TensorDataset(state_train, predict_price_train), batch_size=5, shuffle=True)\n",
    "# test_loader = DataLoader(TensorDataset(state_test, predict_price_test), batch_size=1)\n",
    "state_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct NN\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_observations):\n",
    "        super(NN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some initail parameters \n",
    "LR = 1e-3\n",
    "Weight_decay = 0.01\n",
    "n_observations = len(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_net is your prediction function, take state as input and output is the prediction price\n",
    "value_net = NN(n_observations).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'optimize'  is an easy package to do Gredient decent, 'Adam' is a method to let learing rate decay as step go.\n",
    "optimizer = optim.Adam(value_net.parameters(), lr=LR, weight_decay = Weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimazation function, it do one step of gredient decent, \n",
    "def optimize_model():\n",
    "    for state, target in train_loader:\n",
    "        current_value=value_net(state)                \n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss=criterion(current_value,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for state, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            test_valur=value_net(state)                \n",
    "            l_test=criterion(current_value,target)\n",
    "    return loss.item(),l_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs=1000\n",
    "for epoch in range(epochs):\n",
    "    l_train,l_test=optimize_model()\n",
    "    if epoch % 100 ==0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], L_train: {l_train},L_test: {l_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
