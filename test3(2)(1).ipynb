{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('TSLA_stock_data_2023.csv')\n",
    "# data_day = pd.read.csv('TSLA_stock_data_day_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1847e+02, 1.1880e+02, 1.1035e+02, 1.1106e+02, 6.5616e+07, 1.1105e+02,\n",
      "        1.1224e+02, 1.0805e+02, 1.0847e+02, 3.3929e+07, 1.0847e+02, 1.0850e+02,\n",
      "        1.0560e+02, 1.0615e+02, 3.3451e+07, 1.0615e+02, 1.0648e+02, 1.0464e+02,\n",
      "        1.0567e+02, 2.4088e+07, 1.0567e+02, 1.0745e+02, 1.0534e+02, 1.0732e+02,\n",
      "        2.3360e+07, 1.0732e+02, 1.0940e+02, 1.0677e+02, 1.0808e+02, 2.9563e+07,\n",
      "        1.0809e+02, 1.0875e+02, 1.0752e+02, 1.0806e+02, 1.5564e+07, 1.0911e+02,\n",
      "        1.1274e+02, 1.0752e+02, 1.1072e+02, 6.0188e+07, 1.1069e+02, 1.1244e+02,\n",
      "        1.0993e+02, 1.1230e+02, 2.6007e+07, 1.1232e+02, 1.1459e+02, 1.1225e+02,\n",
      "        1.1275e+02, 2.5649e+07, 1.1275e+02, 1.1294e+02, 1.1143e+02, 1.1276e+02,\n",
      "        1.4665e+07, 1.1276e+02, 1.1430e+02, 1.1184e+02, 1.1203e+02, 2.3124e+07,\n",
      "        1.1202e+02, 1.1394e+02, 1.1190e+02, 1.1301e+02, 1.6542e+07, 1.1301e+02,\n",
      "        1.1372e+02, 1.1225e+02, 1.1364e+02, 1.0188e+07, 1.1051e+02, 1.1133e+02,\n",
      "        1.0744e+02, 1.0842e+02, 4.9873e+07, 1.0841e+02, 1.0896e+02, 1.0716e+02,\n",
      "        1.0860e+02, 2.2871e+07, 1.0859e+02, 1.1052e+02, 1.0836e+02, 1.0999e+02,\n",
      "        2.0578e+07, 1.0998e+02, 1.1175e+02, 1.0921e+02, 1.1108e+02, 1.8166e+07,\n",
      "        1.1109e+02, 1.1145e+02, 1.1010e+02, 1.1012e+02, 1.6738e+07, 1.1011e+02,\n",
      "        1.1133e+02, 1.0997e+02, 1.1059e+02, 1.7126e+07, 1.1060e+02, 1.1086e+02,\n",
      "        1.1006e+02, 1.1037e+02, 8.7495e+06], device='cuda:0')\n",
      "tensor([113.0300], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty lists for states and predict_price\n",
    "states = []\n",
    "predict_prices = []\n",
    "\n",
    "# Set your rolling window size (3 days)\n",
    "rolling_window_size = 3\n",
    "\n",
    "# Start your window from the beginning of the data\n",
    "current_start_index = 0\n",
    "\n",
    "# Calculate the end index for the first window\n",
    "current_end_index = rolling_window_size * 7  # assuming hourly data\n",
    "while current_end_index < len(data)-7:\n",
    "    # Get the current window of data\n",
    "    current_window = data.iloc[current_start_index:current_end_index]\n",
    "    \n",
    "    # Flatten the data from the current window and append it to states\n",
    "    window_features = current_window[['Open', 'High', 'Low', 'Close', 'Volume']].values.flatten()\n",
    "    states.append(window_features)\n",
    "    \n",
    "    # We assume 'Close' price is what we want to predict and use the last 'Close' price of the current window\n",
    "    predict_prices.append(data.iloc[current_end_index+6]['Close'])\n",
    "    \n",
    "    # Move the window one day forward\n",
    "    current_start_index += 1  # assuming hourly data\n",
    "    current_end_index += 1\n",
    "# Convert the lists to NumPy arrays\n",
    "states = np.array(states)\n",
    "predict_prices = np.array(predict_prices)\n",
    "\n",
    "# Convert arrays to tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "predict_prices_tensor = torch.tensor(predict_prices, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# Now you can check the first state and price\n",
    "print(states_tensor[0])  # First state\n",
    "print(predict_prices_tensor[0])  # First price to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.54490005e+02, 2.56980011e+02, 2.52910004e+02, 2.56170013e+02,\n",
       "        2.35974050e+07, 2.56160004e+02, 2.57479004e+02, 2.55389999e+02,\n",
       "        2.56394989e+02, 1.63013580e+07, 2.56409698e+02, 2.57519012e+02,\n",
       "        2.56100006e+02, 2.57445007e+02, 1.09132680e+07, 2.57440186e+02,\n",
       "        2.57820007e+02, 2.56589996e+02, 2.57720001e+02, 1.00004970e+07,\n",
       "        2.57730011e+02, 2.57970001e+02, 2.57210205e+02, 2.57502991e+02,\n",
       "        7.48659400e+06, 2.57510010e+02, 2.57630005e+02, 2.56179993e+02,\n",
       "        2.56855011e+02, 9.02844900e+06, 2.56869995e+02, 2.57459991e+02,\n",
       "        2.56339996e+02, 2.56709991e+02, 6.31647400e+06, 2.58350006e+02,\n",
       "        2.63339996e+02, 2.57519989e+02, 2.62839996e+02, 3.54315110e+07,\n",
       "        2.62829987e+02, 2.62950012e+02, 2.60690002e+02, 2.62250000e+02,\n",
       "        1.76088960e+07, 2.62244995e+02, 2.62959991e+02, 2.61920013e+02,\n",
       "        2.62464996e+02, 1.03576300e+07, 2.62480011e+02, 2.62920013e+02,\n",
       "        2.61829987e+02, 2.62842896e+02, 9.86631300e+06, 2.62850006e+02,\n",
       "        2.63249908e+02, 2.61609985e+02, 2.62239899e+02, 1.04377090e+07,\n",
       "        2.62239990e+02, 2.62440002e+02, 2.60142487e+02, 2.60589996e+02,\n",
       "        9.09913300e+06, 2.60579987e+02, 2.61549988e+02, 2.60450012e+02,\n",
       "        2.61549988e+02, 1.00756260e+07, 2.63660004e+02, 2.65130005e+02,\n",
       "        2.59820007e+02, 2.60876801e+02, 3.24311360e+07, 2.60870087e+02,\n",
       "        2.61760010e+02, 2.58600006e+02, 2.59000000e+02, 1.78276340e+07,\n",
       "        2.59000000e+02, 2.59420013e+02, 2.58299988e+02, 2.58980011e+02,\n",
       "        1.15633090e+07, 2.58980011e+02, 2.59869995e+02, 2.56480011e+02,\n",
       "        2.56692993e+02, 1.30463230e+07, 2.56705292e+02, 2.57179901e+02,\n",
       "        2.55440002e+02, 2.56010010e+02, 1.08631660e+07, 2.56019989e+02,\n",
       "        2.56070007e+02, 2.52710007e+02, 2.53965500e+02, 1.53134970e+07,\n",
       "        2.53960007e+02, 2.54479996e+02, 2.52800003e+02, 2.53190002e+02,\n",
       "        9.11528200e+06]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert state.shape[0] == predict_price.shape[0], \"The number of samples should be the same.\"\n",
    "# Now, use train_test_split\n",
    "state_train, state_test, predict_price_train, predict_price_test = train_test_split(\n",
    "    state, predict_price, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# # divide the data into training part and test part\n",
    "# state_train, state_test, predict_price_train,predict_price_test= train_test_split(state, predict_price,test_size=0.2, random_state=42)\n",
    "# train_loader = DataLoader(TensorDataset(state_train, predict_price_train), batch_size=5, shuffle=True)\n",
    "# test_loader = DataLoader(TensorDataset(state_test, predict_price_test), batch_size=1)\n",
    "state_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct NN\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_observations):\n",
    "        super(NN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some initail parameters \n",
    "LR = 1e-3\n",
    "Weight_decay = 0.01\n",
    "n_observations = len(state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_net is your prediction function, take state as input and output is the prediction price\n",
    "value_net = NN(n_observations).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'optimize'  is an easy package to do Gredient decent, 'Adam' is a method to let learing rate decay as step go.\n",
    "optimizer = optim.Adam(value_net.parameters(), lr=LR, weight_decay = Weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimazation function, it do one step of gredient decent, \n",
    "def optimize_model():\n",
    "    for state, target in train_loader:\n",
    "        current_value=value_net(state)                \n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss=criterion(current_value,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for state, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            test_valur=value_net(state)                \n",
    "            l_test=criterion(current_value,target)\n",
    "    return loss.item(),l_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs=1000\n",
    "for epoch in range(epochs):\n",
    "    l_train,l_test=optimize_model()\n",
    "    if epoch % 100 ==0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], L_train: {l_train},L_test: {l_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
